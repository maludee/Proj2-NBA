{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import json\n",
    "\n",
    "rosters_dict = {}\n",
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "class bball(scrapy.Spider):\n",
    "    name = \"bballref\"\n",
    "    custom_settings = {\n",
    "        \"DOWNLOAD_DELAY\" : 2,\n",
    "        \"CONCURRENT_REQUESTS_PER_DOMAIN\" : 2\n",
    "        }\n",
    "\n",
    "    # Below two are scrapy convention to initialize and close \n",
    "    # Also driver so that you can refer to that instead of typing out webdriver.Chrome\n",
    "    def __init__(self):\n",
    "        self.driver = webdriver.Chrome(chromedriver)\n",
    "        scrapy.Spider.__init__(self)\n",
    "    \n",
    "    # Close after last reference to spider\n",
    "    def __del__(self):\n",
    "        scrapy.Spider.__del__(self)\n",
    "    \n",
    "    # starting point URL for spider. start_requests is the method called to open the spider for scraping\n",
    "    # callback passes instance to the next thing.\n",
    "    def start_requests(self):\n",
    "        url = 'http://www.basketball-reference.com/leagues/NBA_2016.html'\n",
    "        yield scrapy.Request(url = url, callback = self.team_links)\n",
    "        \n",
    "    # Gets URLs for all of the team links from the initial league table\n",
    "    def team_links(self, response):\n",
    "        team_urls = response.xpath('//div[contains(@id, \"all_confs_standings\")]//a')\n",
    "        for i in team_urls:\n",
    "            name = i.xpath('./text()').extract()[0]\n",
    "            print name\n",
    "            url_stub = i.xpath('./@href').extract()[0]\n",
    "            url = 'http://www.basketball-reference.com'+ url_stub\n",
    "            yield scrapy.Request(url = url, callback = self.get_stats, meta = {'team':name})\n",
    "    \n",
    "    # Gets actual player stats         \n",
    "    def get_stats(self, response):\n",
    "        team = response.request.meta['team']\n",
    "        player_list = []\n",
    "        # Feed URL to selenium\n",
    "        self.driver.get(response.url)\n",
    "        # Maximize selenium window (means process has started)\n",
    "        self.driver.maximize_window()\n",
    "        # Give time for page to load\n",
    "        time.sleep(3)\n",
    "        # Find totals table and loop through each row by player to get stats \n",
    "        for i in self.driver.find_elements_by_xpath('//table[@id=\"totals\"]//tbody//tr'):\n",
    "            try:\n",
    "                player_name = i.find_element_by_xpath('.//td[@data-stat=\"player\"]').text\n",
    "                minutes_played =  i.find_element_by_xpath('.//td[@data-stat=\"mp\"]').text\n",
    "                games_played = i.find_element_by_xpath('.//td[@data-stat=\"g\"]').text\n",
    "                games_started = i.find_element_by_xpath('.//td[@data-stat=\"gs\"]').text\n",
    "                points = i.find_element_by_xpath('.//td[@data-stat=\"pts\"]').text\n",
    "                # create a tuple for each player, append to list\n",
    "                player = (player_name, minutes_played, games_played, games_started, points)\n",
    "                player_list.append(player)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return player_list\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TeamLinksSpider(scrapy.Spider):\n",
    "    name = 'teamlinks'\n",
    "    start_urls = [\n",
    "        'http://www.basketball-reference.com/leagues/NBA_2016.html'\n",
    "    ]\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for i in response.xpath('//div[contains(@id, \"all_confs_standings\")]//a/@href').extract():\n",
    "            print 'http://www.basketball-reference.com' + i"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
